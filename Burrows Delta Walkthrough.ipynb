{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough for using the Fast Stylometry model for Burrows' Delta\n",
    "\n",
    "You can run this notebook in Google Colab: <a href=\"https://colab.research.google.com/github/fastdatascience/faststylometry/blob/main/Burrows%20Delta%20Walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "By [Thomas Wood](https://freelancedatascientist.net), [Fast Data Science](https://fastdatascience.com)\n",
    "\n",
    "Burrows' Delta is an algorithm for comparing the similarity of the writing styles of documents, known as [forensic stylometry](https://fastdatascience.com/how-you-can-identify-the-author-of-a-document/).\n",
    "\n",
    "* [A useful explanation of the maths and thinking behind Burrows' Delta and how it works](https://programminghistorian.org/en/lessons/introduction-to-stylometry-with-python#third-stylometric-test-john-burrows-delta-method-advanced)\n",
    "\n",
    "Demonstration of Burrows' Delta on a small corpus downloaded from Project Gutenberg.\n",
    "\n",
    "We will test the Burrows' Delta code on two \"unknown\" texts: Sense and Sensibility by Jane Austen, and Villette by Charlotte Bronte. Both authors are in our training corpus.\n",
    "\n",
    "This notebook demonstrates how to use the library to calculate the Burrows' Delta value of six candidate authors, and also to calculate the probability that each one is the author of the mystery text.\n",
    "\n",
    "\n",
    "You can also read the [tutorial](https://fastdatascience.com/fast-stylometry-python-library/) or try out the [live demo of the tool](https://fastdatascience.com/forensic-stylometry-linguistics-authorship-analysis-demo/).\n",
    "\n",
    "## First install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faststylometry in /home/thomas/anaconda3/lib/python3.11/site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy==1.24.3 in /home/thomas/anaconda3/lib/python3.11/site-packages (from faststylometry) (1.24.3)\n",
      "Requirement already satisfied: pandas==2.1.0 in /home/thomas/anaconda3/lib/python3.11/site-packages (from faststylometry) (2.1.0)\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in /home/thomas/anaconda3/lib/python3.11/site-packages (from faststylometry) (1.3.0)\n",
      "Requirement already satisfied: wget==3.2 in /home/thomas/anaconda3/lib/python3.11/site-packages (from faststylometry) (3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/thomas/anaconda3/lib/python3.11/site-packages (from pandas==2.1.0->faststylometry) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/thomas/anaconda3/lib/python3.11/site-packages (from pandas==2.1.0->faststylometry) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/thomas/anaconda3/lib/python3.11/site-packages (from pandas==2.1.0->faststylometry) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/thomas/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.3.0->faststylometry) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/thomas/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.3.0->faststylometry) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/thomas/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.3.0->faststylometry) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/thomas/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.1.0->faststylometry) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install faststylometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from faststylometry import Corpus\n",
    "\n",
    "from faststylometry import download_examples\n",
    "from faststylometry import load_corpus_from_folder\n",
    "from faststylometry import tokenise_remove_pronouns_en\n",
    "from faststylometry import calculate_burrows_delta\n",
    "from faststylometry import predict_proba, calibrate, get_calibration_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the example corpus (Project Gutenberg texts) from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into Fast Stylometry library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = load_corpus_from_folder(\"data/train\")\n",
    "\n",
    "train_corpus.tokenise(tokenise_remove_pronouns_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load two books by \"unknown\" authors to test the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sense and Sensibility, written by Jane Austen (marked as \"janedoe\")\n",
    "# and Villette, written by Charlotte Bronte (marked as \"currerbell\", Bronte's real pseudonym)\n",
    "\n",
    "test_corpus = load_corpus_from_folder(\"data/test\", pattern=None)\n",
    "# You can set pattern to a string value to just load a subset of the corpus.\n",
    "\n",
    "test_corpus.tokenise(tokenise_remove_pronouns_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Burrows' Delta for both candidate authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_burrows_delta(train_corpus, test_corpus, vocab_size = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate the model and calculate the probability of each candidate in the training set being the author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba(train_corpus, test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the calibration curve\n",
    "\n",
    "We have used Scikit Learn's Logistic Regression to calculate the calibration curve of the model. You could also use your own calibration curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_values =  np.arange(0, 3, 0.1)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_values, train_corpus.probability_model.predict_proba(np.reshape(x_values, (-1, 1)))[:,1])\n",
    "plt.xlabel(\"Burrows delta\")\n",
    "plt.ylabel(\"Probability of same author\")\n",
    "plt.title(\"Calibration curve of the Burrows Delta probability model\\nUsing Logistic Regression with correction for class imbalance\")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the ROC curve\n",
    "\n",
    "The ROC curve and the AUC metric are useful ways of measuring the performance of a classifier.\n",
    "\n",
    "In our case the Burrows' Delta method, when used as a two-class text classifier (different author vs. same author), has an incredibly easy task, because it has learnt from entire books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ground_truths, deltas = get_calibration_curve(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = train_corpus.probability_model.predict_proba(np.reshape(deltas, (-1, 1)))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(ground_truths, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         label='ROC curve (area = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating curve of the Burrows\\' Delta classifier\\noperating on entire books')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment the corpus and display the various books in a scatter graph using PCA\n",
    "\n",
    "Scatter graph shows books' stylistic similarities by placing similar books or segments close together in 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the training corpus as the \"test corpus\", re-tokenise it, and segment it this time\n",
    "test_corpus = load_corpus_from_folder(\"data/train\")\n",
    "test_corpus.tokenise(tokenise_remove_pronouns_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_test_corpus = test_corpus.split(80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta = calculate_burrows_delta(train_corpus, split_test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = split_test_corpus.author_z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_matrix = pca_model.fit_transform(z_scores.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = split_test_corpus.authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_by_author = pd.DataFrame(pca_matrix)\n",
    "df_pca_by_author[\"author\"] = authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15)) \n",
    "\n",
    "for author, pca_coordinates in df_pca_by_author.groupby(\"author\"):\n",
    "    plt.scatter(*zip(*pca_coordinates.drop(\"author\", axis=1).to_numpy()), label=author)\n",
    "for i in range(len(pca_matrix)):\n",
    "    plt.text(pca_matrix[i][0], pca_matrix[i][1],\"  \" + authors[i], alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Representation using PCA of works in training corpus\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
